アドバンスドビジョンの課題レポジトリです

# CIFAR-10におけるCNNのBatch Normalizationの有無と学習データ量の影響比較
## 概要
CIFAR-10画像分類タスクにおいて畳み込みニューラルネットワーク（CNN）に
Batch Normalization（BN）を導入した場合と導入しない場合の学習挙動および分類性能を比較した．

また, 学習データ数を3段階に変化させることでデータ量がBNの効果に与える影響を検証した。

## 参考にしたサイトとの違い
- 入力画像の正規化
- Batch Normalization の導入
- 学習データ数を変えて比較実験

### 入力画像の正規化
画素値のスケールを揃えることで勾配の大きさが安定し,
誤差逆伝播による最適化が進みやすくなるため.

```
X_train_all = X_train_all.astype("float32") / 255.0
X_test_all  = X_test_all.astype("float32")  / 255.0
```

### Batch Normalization の導入
畳み込み層および全結合層の直後にBatch Normalization 層を挿入したモデルを新たに構築し, 
導入しない場合との比較を行った.

本実験では、学習データ数の違いによって
Batch Normalization の効果がどの程度現れるかを検証する目的で導入した.

```
bn_settings = [
    (False, "noBN"),
    (True,  "withBN"),
]

model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))
if use_bn: model.add(BatchNormalization())
model.add(Activation('relu'))

for use_bn, bn_tag in bn_settings:
    for n_train, n_test in settings:
        model = build_model(input_shape=X_train.shape[1:], use_bn=use_bn)


```

## 学習データ数を変えて比較実験
学習データ数および評価データ数を段階的に変化させ, 同一モデル構成のまま学習曲線と最終性能を比較した.

訓練データ数：300 / 3,000 / 50,000
テストデータ数：100 / 1,000 / 10,000

Batch Normalization の効果がデータ数によってどのように変化するかを確認するためである．

```
settings = [
    (300, 100),
    (3000, 1000),
    (50000, 10000),
]

    X_train = X_train_all[:n_train]
    y_train = y_train_all[:n_train]
    X_test  = X_test_all[:n_test]
    y_test  = y_test_all[:n_test]
```

## 実験条件
### データセット
- CIFAR-10（32×32 RGB画像、10クラス）

### 固定条件
| 条件 | 内容 |
|----|----|
| エポック数 | 10 |
| バッチサイズ | 100 |
| 最適化手法 | RMSprop（lr=0.0001） |
| 損失関数 | categorical crossentropy |

### 比較条件
| 条件 | 内容 |
|---|---|
| Batch Normalization | あり / なし |
| 訓練データ数 | 300 / 3,000 / 50,000 |
| テストデータ数 | 100 / 1,000 / 10,000 |


## 実験結果
| BN     | Train size | Test size | Test loss | Test accuracy |
|--------|------------|-----------|-----------|---------------|
| noBN   | 300        | 100       | 2.27      | 0.06          |
| withBN | 300        | 100       | 2.33      | 0.07          |
| noBN   | 3000       | 1000      | 1.82      | 0.37          |
| withBN | 3000       | 1000      | 3.45      | 0.12          |
| noBN   | 50000      | 10000     | 1.16      | 0.60          |
| withBN | 50000      | 10000     | 0.86      | 0.70          |



## 考察
学習データ数が少ない場合はBatch Normalization の効果はほとんど見られず，中程度のデータ数では逆に性能が低下する場合も確認された．
一方，学習データ数が十分に多い条件ではBNありモデルが高い精度と低い損失を示し，学習の安定化と汎化性能向上が確認できた．




# CNNについて

畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）は，画像の局所領域に注目して特徴を抽出し，
層を重ねることで画像全体の特徴を捉えるニューラルネットワークである.

CNNは主に以下の層から構成される.

- 畳み込み層（Convolutional Layer）
- プーリング層（Pooling Layer）
- ソフトマックス層（Softmax Layer / 分類層）

---

## 畳み込み層（Convolutional Layer）

### 局所領域への写像

入力画像の一部である  
$n \times n$ 画素の正方領域（窓）を考える.

この領域内の画素値を  
$x(i, j)$  

対応するフィルタ（重み）を  
$w(i, j)$  

とすると，畳み込み層の出力 $y$ は次式で与えられる.

$$
y = \sum_{i=1}^{n} \sum_{j=1}^{n} w(i, j)\,x(i, j) + b
$$

ここで，

- $x(i, j)$：入力画像の画素値  
- $w(i, j)$：フィルタの重み 
- $b$：バイアス  

である。

この演算はアダマール積（要素ごとの積）を取り，総和する操作に相当する.

---

### フィルタのスライド（ストライド）

フィルタを画像上でずらしながら適用する.

- ストライド = 1： 1画素ずつ移動  
- ストライド > 1： 間引きながら移動  

画像サイズを保ちたい場合にはパディングを行う.

---

### フィルタの意味

フィルタは，

- エッジ
- 方向性
- 局所的な濃度変化

などの局所特徴を検出する役割を持つ.

CNNでは，フィルタの重み $w(i, j)$ 自体を
誤差逆伝播法によって学習する点が特徴である.

---

## チャネル（Channel）

カラー画像（RGB）の場合，入力は

$$
X \in \mathbb{R}^{H \times W \times 3}
$$

となり，各画素は3次元ベクトルとして扱われる.

- 1つのフィルタは全チャネルに対して重みを持つ  
- 各チャネルでの畳み込み結果を足し合わせて1つの出力を生成  

また，複数のフィルタを用いることで出力チャネル数を増やすことができる.

---

## プーリング層（Pooling Layer）

### 目的

プーリング層の目的は以下の通りである.

- 特徴の強い画素を残す  
- 画素数を減らす  
- 位置ズレに対する頑健性を高める  

---

### Max Pooling

プーリング領域 $\Omega$ に対し，Max Pooling は次式で定義される.

$$
y = \max_{(i,j) \in \Omega} x(i, j)
$$

プーリング層では学習は行われない.

---

## ソフトマックス層（Softmax Layer）

### 出力の意味

ソフトマックス層は，最終的な分類結果を
確率として出力するための層である.

---

### 数式

入力ベクトル

$$
x = (x_1, x_2, \dots, x_n)
$$

に対し，ソフトマックス関数は

$$
y_i = \eta e^{x_i}
$$

ただし，正規化定数 $\eta$ は

$$
\eta = \frac{1}{\sum_{j=1}^{n} e^{x_j}}
$$

とすることで，

$$
\sum_{i=1}^{n} y_i = 1
$$

が成り立つ.

---

## CNN全体の処理の流れ

各畳み込み層では次の演算が繰り返し適用される.

$$
y^{(l)} = \sum w^{(l)} x^{(l)} + b^{(l)}
$$

ここで，

- $x^{(l)}$：第 $l$ 層への入力  
- $w^{(l)}$：第 $l$ 層のフィルタ重み  
- $b^{(l)}$：第 $l$ 層のバイアス  
- $y^{(l)}$：第 $l$ 層の出力  

である。

下位層ではエッジや角などの局所特徴が抽出され，
上位層では物体や形状といったより抽象的・全体的特徴が抽出される.

## 参考資料
- https://qiita.com/setowatson/items/ffa9c60023965fe14e6c
- https://qiita.com/momoyama/items/aecf831fbf887f067d42

